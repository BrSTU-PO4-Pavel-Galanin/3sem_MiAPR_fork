{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>Минимстерство образования Республики Беларусь</center>\n",
    "\n",
    "<center>Учреждение образования</center>\n",
    "\n",
    "<center><<Брестский государственный технический университет>></center>\n",
    "\n",
    "<center>Кафедра ИИТ</center>\n",
    "\n",
    "<br /><br /><br /><br /><br /><br />\n",
    "\n",
    "<center>Лабораторная работа №5</center>\n",
    "\n",
    "<center>за 3 семестр</center>\n",
    "\n",
    "<center>по дисциплине: \"Методы и алгоритмы принятия решений\"</center>\n",
    "\n",
    "<center>Тема: \"Нелинейные ИНС в задачах распознавания образов\"</center>\n",
    "\n",
    "<br /><br /><br /><br /><br /><br />\n",
    "\n",
    "<div style=\"display: table; width: 100%;\">\n",
    "    <div style=\"float: right; width: 33%;\">\n",
    "        <p>Выполнил:</p>\n",
    "        <p>студент 2 курса</p>\n",
    "        <p>факультета ЭИС</p>\n",
    "        <p>группы ПО-4(1)</p>\n",
    "        <p>Галанин П. И.</p>\n",
    "        <br />\n",
    "        <p>Проверил:</p>\n",
    "        <p>ст. преподаватель</p>\n",
    "        <p>Крощенко А. А.</p>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "<br /><br /><br /><br /><br /><br />\n",
    "\n",
    "<center>Брест 2020</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лабораторная работа №5\n",
    "\n",
    "**Тема**: Нелинейные ИНС в задачах распознавания образов.\n",
    "\n",
    "**Цель работы**: Изучить обучение и функционирование нелинейной ИНС при решении задач распознавания образов.\n",
    "\n",
    "\n",
    "**Теоретические сведения**.\n",
    "\n",
    "Для решения задач распознавания образов используется следующая нейросетевая архитектура. За основу берется многослойная ИНС прямого распространения. Количество нейронов во входном слое равно длине вектора, представляющего образ. Количество выходных нейронов равно количеству образов и каждому нейрону ставится в соответствие образ. Число нейронных элементов в скрытом слое варьируется для достижения оптимального качества распознавания. Распознавание происходит так. Сначала сеть обучается на наборе пар вектор (он же входной образ) - код этого вектора. Код представляет собой битовую последовательность, в которой один из битов выставлен в единицу, а все остальные нули. Номер этого бита - номер образа, подаваемого на вход. Затем происходит собственно распознавание. На вход сети подается неизвестный вектор. Он обрабатывается ИНС, и на выходе мы получаем код этого вектора. Вектор может быть искажен помехами.\n",
    "\n",
    "Пример применения данного механизма на практике. Векторы могут представлять собой изображения десятичных цифр, закодированные в битовой матрице 4Х4. \n",
    "\n",
    "**Порядок выполнения работы**.\n",
    "1. Изучить теоретические сведения, приведенные в данных методических указания и методических указаниях для работ №3 и №4. \n",
    "2. Написать на любом ЯВУ программу моделирования нелинейной ИНС для распознавания образов. Рекомендуется использовать сигмоидную функцию, но это не является обязательным. Количество НЭ в скрытом слое взять согласно варианту работы №3. Его можно варьировать, если сеть не обучается или некорректно функционирует.\n",
    "3. Провести исследование полученной модели. При этом на вход сети необходимо подавать искаженные образы, в которых инвертированы некоторые биты. Критерий эффективности процесса распознавания - максимальное кодовое расстояние (количество искаженных битов) между исходным и поданным образом.\n",
    "4. Оформить отчет, содержащий:\n",
    "    1. Титульный лист,\n",
    "    2. Цель работы,\n",
    "    3. Задание,\n",
    "    4. График изменения ошибки в зависимости от итерации.\n",
    "    5. Описание результатов распознавания.\n",
    "    6. Выводы по лабораторной работе.\n",
    " \n",
    "Таблица 1. Варианты заданий.\n",
    "\n",
    "|Вариант|Вектор 1|Вектор 2|Вектор 3|\n",
    "|-------|--------|--------|--------|\n",
    "|1      |1       |6       |8       |\n",
    "|2      |2       |1       |8       |\n",
    "|3      |3       |2       |8       |\n",
    "|4      |4       |3       |8       |\n",
    "|5      |5       |4       |8       |\n",
    "|6      |6       |5       |8       |\n",
    "|7      |7       |6       |8       |\n",
    "|8      |1       |3       |8       |\n",
    "|9      |2       |4       |8       |\n",
    "|10     |3       |5       |8       |\n",
    "|11     |4       |6       |8       |\n",
    "\n",
    "Таблица 2. Набор векторов.\n",
    "\n",
    "№ Данные вектора\n",
    "\n",
    "|№|  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\n",
    "|-|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|\n",
    "|1| 0| 1| 0| 0| 1| 1| 0| 1| 0| 0| 0| 0| 1| 0| 1| 0| 1| 0| 0| 0|\n",
    "|2| 0| 0| 0| 0| 1| 1| 1| 1| 0| 0| 0| 0| 1| 1| 1| 1| 0| 0| 0| 0|\n",
    "|3| 1| 1| 1| 1| 0| 0| 0| 0| 1| 1| 1| 1| 0| 0| 0| 0| 1| 1| 1| 1|\n",
    "|4| 1| 1| 0| 0| 1| 1| 0| 0| 1| 1| 0| 0| 1| 1| 0| 0| 1| 1| 0| 0|\n",
    "|5| 1| 0| 1| 0| 1| 0| 1| 0| 1| 0| 1| 0| 1| 0| 1| 0| 1| 0| 1| 0|\n",
    "|6| 1| 1| 1| 1| 1| 1| 1| 1| 0| 0| 0| 0| 0| 0| 0| 0| 0| 0| 0| 0|\n",
    "|7| 0| 0| 0| 0| 0| 0| 0| 0| 1| 1| 1| 1| 1| 1| 1| 1| 1| 1| 1| 1|\n",
    "|8| 1| 1| 1| 0| 0| 0| 1| 1| 1| 0| 0| 0| 1| 1| 1| 0| 0| 0| 1| 1|\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import random\n",
    "import matplotlib.pyplot\n",
    "\n",
    "class lab5:\n",
    "    # Функция принимает параметры:\n",
    "    # variant - number neurons for learning\n",
    "    # Ee - desired squared error\n",
    "    # alpha_ki - learning rate (inputs - hiddens)\n",
    "    # alpha_ij - learning rate (hiddens - outputs)\n",
    "    def __init__(self, variant, maxIterations, Ee, alpha_ki, alpha_ij):\n",
    "        print('\\nObject lab5 are created\\n')\n",
    "\n",
    "        self.variant = variant\n",
    "        self.maxIterations = maxIterations\n",
    "        self.Ee = Ee\n",
    "        self.alpha_ki = alpha_ki\n",
    "        self.alpha_ij = alpha_ij\n",
    "\n",
    "        self.etalons = self.get_etalons(self.variant)\n",
    "        #print(self.etalons)\n",
    "\n",
    "        self.inputs = len(self.etalons[0])\n",
    "        #print(inputs)\n",
    "\n",
    "        self.hiddens = self.inputs # взять столько же?\n",
    "\n",
    "        self.outputs = len(self.etalons)\n",
    "        #print(outputs)\n",
    "\n",
    "        self.weights_ki = self.get_weights(self.inputs, self.hiddens, -1, 1)\n",
    "        #print(weights_ki)\n",
    "\n",
    "        self.weights_ij = self.get_weights(self.hiddens, self.outputs, -1, 1)\n",
    "        #print(weights_ij)\n",
    "\n",
    "        self.tresholds_i = self.get_thresholds(self.hiddens, -1, 1)\n",
    "        #print(tresholds_i)\n",
    "\n",
    "        self.tresholds_j = self.get_thresholds(self.outputs, -1, 1)\n",
    "        #print(tresholds_j)\n",
    "\n",
    "        self.valuesXforGraph = []\n",
    "        self.valuesYforGraph = []\n",
    "\n",
    "    def get_etalons(self, variant):\n",
    "        variant %= 11\n",
    "\n",
    "        Vector_1 = numpy.array([0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0])\n",
    "        Vector_2 = numpy.array([0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0])\n",
    "        Vector_3 = numpy.array([1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1])\n",
    "        Vector_4 = numpy.array([1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0])\n",
    "        Vector_5 = numpy.array([1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0])\n",
    "        Vector_6 = numpy.array([1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "        Vector_7 = numpy.array([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
    "        Vector_8 = numpy.array([1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1])\n",
    "\n",
    "        if variant == 1:\n",
    "            return numpy.array([Vector_1, Vector_6, Vector_8])\n",
    "\n",
    "        elif variant == 2:\n",
    "            return numpy.array([Vector_2, Vector_1, Vector_8])\n",
    "\n",
    "        elif variant == 3:\n",
    "            return numpy.array([Vector_3, Vector_2, Vector_8])\n",
    "\n",
    "        elif variant == 4:\n",
    "            return numpy.array([Vector_4, Vector_3, Vector_8])\n",
    "\n",
    "        elif variant == 5:\n",
    "            return numpy.array([Vector_5, Vector_4, Vector_8])\n",
    "\n",
    "        elif variant == 6:\n",
    "            return numpy.array([Vector_6, Vector_5, Vector_8])\n",
    "\n",
    "        elif variant == 7:\n",
    "            return numpy.array([Vector_7, Vector_6, Vector_8])\n",
    "\n",
    "        elif variant == 8:\n",
    "            return numpy.array([Vector_1, Vector_3, Vector_8])\n",
    "\n",
    "        elif variant == 9:\n",
    "            return numpy.array([Vector_2, Vector_4, Vector_8])\n",
    "\n",
    "        elif variant == 10:\n",
    "            return numpy.array([Vector_3, Vector_5, Vector_8])\n",
    "\n",
    "        elif variant == 0: #11\n",
    "            return numpy.array([Vector_4, Vector_6, Vector_8])\n",
    "\n",
    "        else:\n",
    "            return numpy.array([[], [], []])\n",
    "\n",
    "    # Функция возвращает массив с весами\n",
    "    # Например, 8 нейронов в входном слое и 3 в скрытом, тогда возвратит массив 8х3\n",
    "    # Например, 3 нейрона в скрытом слое и 1 нейрон в выходном слое, тогда возвратит массив 3х1\n",
    "    def get_weights(self, leftNumberNeurons, rightNumberNeurons, leftRandomBorder, rightRandomBorder):\n",
    "        weights = numpy.zeros((leftNumberNeurons, rightNumberNeurons))\n",
    "        for i in range(leftNumberNeurons):\n",
    "            for j in range(rightNumberNeurons):\n",
    "                weights[i][j] = random.uniform(leftRandomBorder, rightRandomBorder)\n",
    "        return weights\n",
    "\n",
    "    # Функция возвращает массив с порогами\n",
    "    # Например, 8 нейронов в входном слое и 3 в скрытом, тогда возвратит массив размером 3\n",
    "    # Например, 3 нейрона в скрытом слое и 1 нейрон в выходном слое, тогда возвратит массив размером 1\n",
    "    def get_thresholds(self, numberNeurons, leftRandomBorder, rightRandomBorder):\n",
    "        tresholds = numpy.zeros(numberNeurons)\n",
    "        for i in range(numberNeurons):\n",
    "            tresholds[i] = random.uniform(leftRandomBorder, rightRandomBorder)\n",
    "        return tresholds\n",
    "\n",
    "    def print_graph(self):\n",
    "        print('\\nFunction lab5 :: print_graph are start\\n')\n",
    "\n",
    "        matplotlib.pyplot.plot(self.valuesYforGraph, self.valuesXforGraph, 'g-o')\n",
    "        matplotlib.pyplot.title('E(eras)')\n",
    "        matplotlib.pyplot.show()\n",
    "\n",
    "        print('\\nFunction lab5 :: print_graph are end\\n')\n",
    "\n",
    "    def learning(self):\n",
    "        print('\\nFunction lab5 :: learning are start\\n')\n",
    "\n",
    "        self.valuesXforGraph = []\n",
    "        self.valuesYforGraph = []\n",
    "        eras = 0\n",
    "        while 1:\n",
    "            sum1 = 0\n",
    "            sum2 = 0\n",
    "            sum3 = 0\n",
    "            for etalon in self.etalons:\n",
    "                # Взвешенная сумма для скрытого слоя\n",
    "                # Si = x * wki - Ti\n",
    "                x = etalon\n",
    "                S_i = x.dot(self.weights_ki) - self.tresholds_i\n",
    "                #print(S_i)\n",
    "\n",
    "                # Выходные значения для скрытого слоя\n",
    "                # yi = Sigm(Si)\n",
    "                y_i = numpy.zeros(len(S_i))\n",
    "                for i in range(len(S_i)):\n",
    "                    y_i[i] = 1. / (1. + numpy.exp( - S_i[i] )) # sigmoid func\n",
    "                #print(y_i)\n",
    "\n",
    "                # Взвешенная сумма для выходного слоя\n",
    "                # Sj = yi * wij - Tj\n",
    "                S_j = y_i.dot(self.weights_ij) - self.tresholds_j\n",
    "                #print(S_j)\n",
    "\n",
    "                # Выходные значения для выходного слоя\n",
    "                # yj = Linear(Sj) = Sj\n",
    "                y_j = S_j\n",
    "                #print(y_j)\n",
    "\n",
    "                # Обратная ошибка для выходного слоя\n",
    "                # jj = yj - e\n",
    "                j_j = numpy.array([ y_j[i] - etalon[i] for i in range(len(y_j)) ])\n",
    "                #print(j_j)\n",
    "\n",
    "                # Обратная ошибка для скрытого слоя\n",
    "                # ji = sum [dF(Sj) * wij]\n",
    "                dF_j = 1\n",
    "                j_i = numpy.zeros(self.hiddens)\n",
    "                for i in range(self.hiddens):\n",
    "                    for j in range(self.outputs):\n",
    "                        j_i[i] += j_j[j] * dF_j * self.weights_ij[i][j]\n",
    "                #print(j_i)\n",
    "\n",
    "                # # Первая сумма для адаптивного шага обучения\n",
    "                # for j in range(outputs):\n",
    "                #     sum1 += j_j[j]**2 * (1 - y_j[j]**2)\n",
    "                # #print(sum1)\n",
    "\n",
    "                # # Вторая сумма для адаптивного шага обучения\n",
    "                # for i in range(hiddens):\n",
    "                #     sum2 += y_i[i]**2\n",
    "                # #print(sum2)\n",
    "\n",
    "                # # Третья сумма для адаптивного шага обучения\n",
    "                # for j in range(outputs):\n",
    "                #     sum3 += j_j[j]**2 * y_j[j]**2 * (1 - y_j[j])**2\n",
    "                # #print(sum3)\n",
    "\n",
    "                # # Адаптивный шаг обучения\n",
    "                # alpha_ki = 4 * sum1 / ( (1 + sum2) * sum3 )\n",
    "\n",
    "                # Веса от скрытого слоя к выходному\n",
    "                # wij = wij - alpha * jj * dFj * yi\n",
    "                for i in range(self.hiddens):\n",
    "                    for j in range(self.outputs):\n",
    "                        self.weights_ij[i][j] -= self.alpha_ij * j_j[j] * dF_j * y_j[j]\n",
    "                #print(weights_ij)\n",
    "\n",
    "                # Пороги выходного слоя\n",
    "                # Tj = Tj + alpha * jj * dFj\n",
    "                for j in range(self.outputs):\n",
    "                    self.tresholds_j += self.alpha_ij * j_j[j] * dF_j\n",
    "                #print(tresholds_j)\n",
    "\n",
    "                # Веса от входного слоя к скрытому\n",
    "                # wki = wki - alpha * ji * dFi * yi\n",
    "                for k in range(self.inputs):\n",
    "                    for i in range(self.hiddens):\n",
    "                        dFi = y_i[i] * (1 - y_i[i]) # derivative sigmoid func\n",
    "                        self.weights_ki[k][i] -= self.alpha_ki * j_i[i] * dFi * y_i[i]\n",
    "                #print(weights_ki)\n",
    "\n",
    "                # Пороги скрытого слоя\n",
    "                # Ti = Ti + alpha * ji * dFi\n",
    "                for i in range(self.hiddens):\n",
    "                    dFi = y_i[i] * (1 - y_i[i]) # derivative sigmoid func\n",
    "                    self.tresholds_i += self.alpha_ki * j_i[i] * dFi\n",
    "                #print(tresholds_i)\n",
    "\n",
    "            # Вычисляем среднюю квадратичную ошибку\n",
    "            E = 0\n",
    "            for j in range(self.outputs):\n",
    "                E += 1./2 * (y_j[j] - etalon[j]) ** 2\n",
    "\n",
    "            # значение x для графика с ошибкой\n",
    "            self.valuesXforGraph.append(E)\n",
    "\n",
    "            eras += 1\n",
    "\n",
    "            # значение y для графика с ошибкой\n",
    "            self.valuesYforGraph.append(eras)\n",
    "\n",
    "            # выводим значения в консоль\n",
    "            print('eras: %8d\\tE: %32.20f\\r' % (eras, E), end = '')\n",
    "            #print('eras: %8d\\tE: %32.20f' % (eras, E))\n",
    "\n",
    "            # условия останова\n",
    "            if E < self.Ee or eras >= self.maxIterations:\n",
    "                print()\n",
    "                break\n",
    "\n",
    "        print('Eras: %d with error E = %f' % (eras, E))\n",
    "\n",
    "        print('\\nFunction lab5 :: learning are end\\n')\n",
    "\n",
    "    def save(self):\n",
    "        # print('weights_ki')\n",
    "        # print(self.weights_ki)\n",
    "\n",
    "        # print('weights_ij')\n",
    "        # print(self.weights_ij)\n",
    "\n",
    "        # print('tresholds_i')\n",
    "        # print(self.tresholds_i)\n",
    "\n",
    "        # print('tresholds_j')\n",
    "        # print(self.tresholds_j)\n",
    "\n",
    "        print('\\nSave weights and tresholds:')\n",
    "        print('y - yes')\n",
    "        print('n - no')\n",
    "        key = input()\n",
    "        if key == 'y':\n",
    "            csv_separator = ', '\n",
    "\n",
    "            fp = open('weights_ki.csv', 'w')\n",
    "            for k in range(self.inputs):\n",
    "                for i in range(self.hiddens):\n",
    "                    fp.write( str(self.weights_ki[k][i]) )\n",
    "                    if i != (self.hiddens - 1):\n",
    "                        fp.write(csv_separator)\n",
    "                if k != (self.inputs - 1):\n",
    "                    fp.write('\\n')\n",
    "            fp.close()\n",
    "\n",
    "            fp = open('weights_ij.csv', 'w')\n",
    "            for i in range(self.hiddens):\n",
    "                for j in range(self.outputs):\n",
    "                    fp.write( str(self.weights_ij[i][j]) )\n",
    "                    if j != (self.outputs - 1):\n",
    "                        fp.write(csv_separator)\n",
    "                if i != (self.hiddens - 1):\n",
    "                    fp.write('\\n')\n",
    "            fp.close()\n",
    "\n",
    "            fp = open('tresholds_i.csv', 'w')\n",
    "            for i in range(self.hiddens):\n",
    "                fp.write( str(self.tresholds_i[i]) )\n",
    "                if i != (self.hiddens - 1):\n",
    "                    fp.write(csv_separator)\n",
    "            fp.close()\n",
    "\n",
    "            fp = open('tresholds_j.csv', 'w')\n",
    "            for j in range(self.outputs):\n",
    "                fp.write( str(self.tresholds_j[j]) )\n",
    "                if j != (self.outputs - 1):\n",
    "                    fp.write(csv_separator)\n",
    "            fp.close()\n",
    "\n",
    "    def test(self, etalon):\n",
    "        # Взвешенная сумма скрытого слоя\n",
    "        # Si = x * wki - Ti\n",
    "        x = numpy.array(etalon)\n",
    "        S_i = x.dot(self.weights_ki) - self.tresholds_i\n",
    "        #print(S_i)\n",
    "\n",
    "        # Выходные значения скрытого слоя\n",
    "        # yi = Sigm(Si)\n",
    "        y_i = numpy.zeros(len(S_i))\n",
    "        for i in range(len(S_i)):\n",
    "            y_i[i] = 1. / (1. + numpy.exp( - S_i[i] )) # sigmoid func\n",
    "        #print(y_i)\n",
    "\n",
    "        # Взвешенная сумма скрытого слоя\n",
    "        # Sj = yi * wij - Tj\n",
    "        S_j = y_i.dot(self.weights_ij) - self.tresholds_j\n",
    "        #print(S_j)\n",
    "\n",
    "        # Выходные значения скрытого слоя\n",
    "        # yj = Linear(Sj) = Sj\n",
    "        y_j = S_j\n",
    "\n",
    "        maxValue = y_j[0]\n",
    "        maxValueIndex = 0\n",
    "        for j in range(self.outputs):\n",
    "            if y_j[j] > maxValue:\n",
    "                maxValue = y_j[j]\n",
    "                maxValueIndex = j\n",
    "\n",
    "        print('y_j = ', y_j)\n",
    "        print('etalon = ', etalon)\n",
    "        print('etalon is class #%d\\n' % (maxValueIndex))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Object lab5 are created\n",
      "\n",
      "\n",
      "Function lab5 :: learning are start\n",
      "\n",
      "eras:     1000\tE:           0.31330785075557665564\n",
      "Eras: 1000 with error E = 0.313308\n",
      "\n",
      "Function lab5 :: learning are end\n",
      "\n",
      "y_j =  [1.35145723 0.49380882 0.50437668]\n",
      "etalon =  [1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1]\n",
      "etalon is class #0\n",
      "\n",
      "y_j =  [1.25493223 0.27001065 0.50815545]\n",
      "etalon =  [0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1]\n",
      "etalon is class #0\n",
      "\n",
      "y_j =  [1.38458097 0.65445933 0.49075243]\n",
      "etalon =  [0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1]\n",
      "etalon is class #0\n",
      "\n",
      "y_j =  [1.4661002  0.88564668 0.47424085]\n",
      "etalon =  [0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1]\n",
      "etalon is class #0\n",
      "\n",
      "y_j =  [1.42886733 0.80933023 0.48058158]\n",
      "etalon =  [0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1]\n",
      "etalon is class #0\n",
      "\n",
      "y_j =  [1.4169145  0.73824848 0.49905682]\n",
      "etalon =  [0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1]\n",
      "etalon is class #0\n",
      "\n",
      "y_j =  [1.45761291 0.84344404 0.4989072 ]\n",
      "etalon =  [0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1]\n",
      "etalon is class #0\n",
      "\n",
      "y_j =  [1.37054554 0.59720377 0.5147225 ]\n",
      "etalon =  [0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1]\n",
      "etalon is class #0\n",
      "\n",
      "y_j =  [1.42714905 0.74457184 0.49192488]\n",
      "etalon =  [0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1]\n",
      "etalon is class #0\n",
      "\n",
      "y_j =  [1.40922959 0.66688156 0.50562075]\n",
      "etalon =  [0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1]\n",
      "etalon is class #0\n",
      "\n",
      "y_j =  [1.32202228 0.49638366 0.4997597 ]\n",
      "etalon =  [0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1]\n",
      "etalon is class #0\n",
      "\n",
      "y_j =  [1.19059161 0.18394641 0.50304872]\n",
      "etalon =  [0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1]\n",
      "etalon is class #0\n",
      "\n",
      "y_j =  [ 1.09866774 -0.14001399  0.50725889]\n",
      "etalon =  [0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1]\n",
      "etalon is class #0\n",
      "\n",
      "y_j =  [ 0.77126133 -1.15691989  0.54220686]\n",
      "etalon =  [0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1]\n",
      "etalon is class #0\n",
      "\n",
      "y_j =  [ 0.65834801 -1.40052915  0.57170202]\n",
      "etalon =  [0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1]\n",
      "etalon is class #0\n",
      "\n",
      "y_j =  [ 0.88590496 -0.98613921  0.5330954 ]\n",
      "etalon =  [0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1]\n",
      "etalon is class #0\n",
      "\n",
      "y_j =  [1.19006052 0.02705498 0.51304581]\n",
      "etalon =  [0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1]\n",
      "etalon is class #0\n",
      "\n",
      "y_j =  [1.22985166 0.25805597 0.50836809]\n",
      "etalon =  [0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1]\n",
      "etalon is class #0\n",
      "\n",
      "y_j =  [1.25853914 0.2329783  0.49047295]\n",
      "etalon =  [0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1]\n",
      "etalon is class #0\n",
      "\n",
      "y_j =  [1.21580825 0.2030202  0.52966909]\n",
      "etalon =  [0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1]\n",
      "etalon is class #0\n",
      "\n",
      "y_j =  [1.27220581 0.45104027 0.52480909]\n",
      "etalon =  [0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0]\n",
      "etalon is class #0\n",
      "\n",
      "y_j =  [1.35940542 0.61345593 0.52239665]\n",
      "etalon =  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "etalon is class #0\n",
      "\n",
      "y_j =  [1.28451393 0.42570868 0.48317486]\n",
      "etalon =  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "etalon is class #0\n",
      "\n",
      "y_j =  [1.22362084 0.20267045 0.58954366]\n",
      "etalon =  [0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0]\n",
      "etalon is class #0\n",
      "\n",
      "y_j =  [1.42501637 0.73002422 0.49553472]\n",
      "etalon =  [0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0]\n",
      "etalon is class #0\n",
      "\n",
      "y_j =  [ 0.18378868 -3.66917649  0.48700546]\n",
      "etalon =  [1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1]\n",
      "etalon is class #2\n",
      "\n",
      "y_j =  [1.34502918 0.57848501 0.50758239]\n",
      "etalon =  [1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0]\n",
      "etalon is class #0\n",
      "\n",
      "y_j =  [1.26619249 0.42179338 0.52509219]\n",
      "etalon =  [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0]\n",
      "etalon is class #0\n",
      "\n",
      "y_j =  [ 1.02474118 -0.36651178  0.67244249]\n",
      "etalon =  [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "etalon is class #0\n",
      "\n",
      "y_j =  [1.23503483 0.17060656 0.47618474]\n",
      "etalon =  [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "etalon is class #0\n",
      "\n",
      "y_j =  [1.35145723 0.49380882 0.50437668]\n",
      "etalon =  [1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1]\n",
      "etalon is class #0\n",
      "\n",
      "\n",
      "Function lab5 :: print_graph are start\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Function lab5 :: print_graph are end\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.seed(3)\n",
    "\n",
    "obj = lab5(\n",
    "    5,      # variant\n",
    "    1000,   # maxIterations - max number of itererations\n",
    "    1e-2,   # Ee - desired squared error\n",
    "    0.001,  # alpha_ki - learning rate (inputs - hiddens)\n",
    "    0.001   # alpha_ij - learning rate (hiddens - outputs)\n",
    ")\n",
    "\n",
    "obj.learning()\n",
    "\n",
    "# Изменяю по одному биту из вектора 8\n",
    "obj.test([1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1])\n",
    "obj.test([0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1])\n",
    "obj.test([0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1])\n",
    "obj.test([0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1])\n",
    "obj.test([0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1])\n",
    "obj.test([0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1])\n",
    "obj.test([0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1])\n",
    "obj.test([0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1])\n",
    "obj.test([0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1])\n",
    "obj.test([0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1])\n",
    "obj.test([0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1])\n",
    "obj.test([0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1])\n",
    "obj.test([0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1])\n",
    "obj.test([0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1])\n",
    "obj.test([0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1])\n",
    "obj.test([0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1])\n",
    "obj.test([0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1])\n",
    "obj.test([0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1])\n",
    "obj.test([0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1])\n",
    "obj.test([0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1])\n",
    "obj.test([0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0])\n",
    "\n",
    "# my vectors\n",
    "obj.test([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "obj.test([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
    "\n",
    "# vector 1 to 8\n",
    "obj.test([0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0])\n",
    "obj.test([0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0])\n",
    "obj.test([1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1])\n",
    "obj.test([1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0])\n",
    "obj.test([1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0])\n",
    "obj.test([1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "obj.test([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
    "obj.test([1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1])\n",
    "\n",
    "#obj.save()\n",
    "obj.print_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод**:\n",
    "- Поменяв образцы из лабораторной работы №3 и сделав 3 (три) выхода на сети, сделал нейронную сеть с классами.\n",
    "- При тестах использовал искаженный вектор 8 (изменял каждый раз один бит - итого 20 раз). Нейронная сеть не поменяла своего мнения.\n",
    "- При тестах использовал вектор заполненый нулями. Нейронная сеть определила как класс 0.\n",
    "- При тестах использовал вектор заполненый нулями. Нейронная сеть определила как класс 0.\n",
    "- При подачи на тест векторов из условия, нейронная сеть один раз определила класс 2, при векторе варианта №3.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
